---
title: "The NystrÃ¶m Method for Convex Loss Functions"
authors: "A. Della Vecchia, E. De Vito, J. Mourtada, L. Rosasco"
venue: "Journal of Machine Learning Research (JMLR)"
date: 2024-11-30
year: 2024
paperurl: "https://jmlr.org/papers/vXX/XXXX.html"   # replace with the actual JMLR URL (or Scholar)
pdf: "/files/papers/nystrom_convex_jmlr_2024.pdf"
selected: true

# Short abstract shown on the publications page (safe folded YAML block)
excerpt: >-
  **Abstract:** This paper addresses the covariate shift problem in the context of nonparametric
  regression within reproducing kernel Hilbert spaces (RKHSs). Covariate shift arises in supervised
  learning when the input distributions of the training and test data differ, presenting additional
  challenges for learning. Although kernel methods have optimal statistical properties, their high
  computational demands in terms of time and, particularly, memory, limit their scalability to large
  datasets. To address this limitation, the main focus of this paper is to explore the trade-off
  between computational efficiency and statistical accuracy under covariate shift. We investigate
  the use of random projections where the hypothesis space consists of a random subspace within a
  given RKHS. Our results show that, even in the presence of covariate shift, significant
  computational savings can be achieved without compromising learning performance.
---
